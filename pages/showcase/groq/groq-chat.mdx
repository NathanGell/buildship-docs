---
title: Buildship - Groq Chat
description: Using the Groq (LLM) Chat Completions API to process messages and generate output responses.
---

import Node from '/components/node';

# Groq Chat
The **Groq Chat** node leverages the Groq (LLM) Chat Completions API to process a series of messages based on provided prompts and generate appropriate output responses.

<Node id="@buildship/groq-chat" version="1.3.0" />

## Inputs
To use the Groq Chat node, youâ€™ll need to specify several inputs:

1. **API Key**
   - **Description:** The API Key for accessing the Groq API. Obtain it from the [GroqCloud API Dashboard](https://console.groq.com/keys).
   - **Sample Input:** `your-api-key`

2. **System Prompt**
   - **Description:** This prompt sets the role of the system for chat completion.
   - **Sample Input:** 
     ```
     You're a helpful assistant.
     ```

3. **User Prompt**
   - **Description:** The user-specific prompt that defines the context or question for the chat completion.
   - **Sample Input:** 
     ```
     Explain the importance of low latency LLMs.
     ```

4. **Model**
   - **Description:** The selected model to process the chat completion. Multiple models are available:
     - `llama3-70b-8192`
     - `llama3-8b-8192`
     - `llama2-70b-4096`
     - `mixtral-8x7b-32768`
     - `gemma-7b-it`
   - **Sample Input:** `llama3-8b-8192`

5. **Temperature**
   - **Description:** Adjusts the randomness of the response generated by the model. The value ranges from 0 to 1, with a default of 0.5.
   - **Sample Input:** `0.7`

## Output
The node returns a string that represents the generated response from the Groq Chat Completions API based on the provided inputs. If there is no response, it defaults to `"No Response"`.
