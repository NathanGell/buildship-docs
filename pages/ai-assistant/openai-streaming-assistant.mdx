---
title: OpenAI Streaming Assistant Node
description:
  The OpenAI Streaming Assistant Node allows you to integrate the OpenAI Assistant API into your workflows and receive
  responses in a streamed format.
---

import { Callout } from 'nextra/components';
import Image from 'next/image';
import { Card, Cards } from 'nextra/components';
import Video from '../../components/video/index.jsx';
import streaming1 from '/public/integrations/ai-assistant/streaming-1.png';

# OpenAI Streaming Assistant Node

The OpenAI Streaming Assistant Node allows you to interact with the powerful OpenAI Assistant API and receive
intelligent responses generated by the OpenAI language model in a streamed format. This node supports the latest version
of the OpenAI API, providing access to the latest features and capabilities.

<Image src={streaming1} alt='OpenAI Streaming Assistant Node' width={1200} />

<Callout>
  This is the streaming version of the OpenAI Assistant Node. If you are looking for the standard version, please refer
  to the [OpenAI Assistant Node](/ai-assistant/openai-assistant).
</Callout>

## Get Started âœ…

To get started quickly, BuildShip offers a pre-built template. Click on the templates below to clone them to your
workspace and start using them right away!

<Cards num={2}>
  <Card
    image
    arrow
    title='An Assistant that streams back a text response and returns the Thread ID as a response header.'
    href='https://buildship.app/remix?template=streaming-assistant'
  >
    <>
      ![An Assistant that streams back a text response and returns the Thread ID as a response
      header.](../../public/remix/openai-streaming.png)
    </>
  </Card>
  <Card
    image
    arrow
    title='BuildShip AI Chat Widget: A pre-built chat widget that integrates with the OpenAI Streaming Assistant.'
    href='https://github.com/rowyio/buildship-chat-widget'
  >
    <>
      ![BuildShip AI Chat Widget: A pre-built chat widget that integrates with the OpenAI Streaming
      Assistant.](../../public/remix/chat-widget.png)
    </>
  </Card>
</Cards>

## Node Inputs

The OpenAI Streaming Assistant Node accepts the same inputs as the OpenAI Assistant Node,
[learn more](/ai-assistant/openai-assistant#node-inputs).

## Node Outputs

### 1. Response Stream

This output property is the stream object to which the AI assistant's response is piped. The client, upon receiving this
object, can accept the response in the form of a stream.

<Callout>
  To have the workflow respond with the text stream, this **Response Stream** object needs to be only value being
  returned by the workflow's **Return node**.
</Callout>

<Video src='/integrations/ai-assistant/streaming-output.mp4' />

### 2. Thread ID

This optional input **allows you to save and share the context of the conversation using a thread ID**. The thread ID
can be any **unique identifier**, such as a UUID or a custom string. The chat history belonging to a specific thread ID
is retrieved and continued in subsequent interactions. This feature is useful for maintaining context and continuity in
multi-turn conversations.

**Sample Thread ID:** `123e4567-e89b-12d3-a456-426614174000`

**If no thread ID is provided, a new conversation thread is started and a new thread ID is generated automatically**.
This Thread ID is also **returned as an output of the Claude Assistant** node for reference. You can make your client
applications store and reuse this thread ID for future interactions.

## Example Use Cases

- **Real-time Assistant:** Integrate the OpenAI Streaming Assistant into your applications to provide real-time
  responses and updates as the assistant generates its response.
- **Multi-turn Conversations:** Maintain context and continuity in multi-turn conversations by using the thread ID
  feature to save and retrieve conversation history.
